{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting automate_rsync.ipynb to automate_rsync.py\n",
      "********** #!/usr/bin/env python3 **********\n",
      "[NbConvertApp] Converting notebook automate_rsync.ipynb to python\n"
     ]
    }
   ],
   "source": [
    "!/Users/aaronciuffo/bin/develtools/nbconvert automate_rsync.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Links:\n",
    "* Subprocess help:\n",
    "    * [running shell commands](https://janakiev.com/blog/python-shell-commands/)\n",
    "    * [excute commands safely](https://supakeen.com/weblog/executing-commands-safely-from-python.html)\n",
    "    \n",
    "# Notes\n",
    "* for testing in Jupyter: \n",
    "```\n",
    "sys_args_initial = sys.argv\n",
    "sys.argv.clear()\n",
    "sys.argv.append('-v')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import logging\n",
    "import tempfile\n",
    "import uuid\n",
    "import re\n",
    "import shlex\n",
    "import subprocess\n",
    "import argparse\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "VERSION = '3.0.09-beta'\n",
    "APP_NAME = 'automate_rsync'\n",
    "DEVEL_NAME = 'com.txoof'\n",
    "CONFIG_FILE = f'{APP_NAME}.ini'\n",
    "\n",
    "\n",
    "EXPECTED_BASE_KEYS = {'rsync_bin': None,\n",
    "                      'rsync_options': '',\n",
    "                      'delete_options': '',\n",
    "                      }\n",
    "\n",
    "EXPECTED_JOB_KEYS = {'direction': 'local-remote',\n",
    "                     'user': None,\n",
    "                     'remotehost': None,\n",
    "                     'sshkey': None,\n",
    "                     'localpath': None,\n",
    "                     'remotepath': None,\n",
    "                     'exclude': [],\n",
    "                     'log_file': '/dev/null',\n",
    "                     'max_log': 0,\n",
    "                     'timeout': None,\n",
    "                     'kill': False,\n",
    "                    }\n",
    "\n",
    "EXPECTED_SSH_KEYS = {'extrassh': ''}\n",
    "\n",
    "CONFIG_PATH = Path(f'~/.config/{DEVEL_NAME}.{APP_NAME}').expanduser().absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_config():\n",
    "    return '''[%base_config]\n",
    "## `rsync_bin`: optional -- path to rsync bin; useful if not in $PATH\n",
    "rsync_bin = None\n",
    "## `rsync_options`: optional -- options to use for all rsync jobs\n",
    "rsync_options = -a -z\n",
    "## `delete_options`: optional -- deletion strategies to use (leave blank for none)\n",
    "delete_options = --delete-excluded\n",
    "\n",
    "[%ssh_opts]\n",
    "## extra options to pass to the ssh module\n",
    "## -e \"ssh <extrassh>\"\n",
    "## -o IdentitiesOnly=yes forces the use of one single key file\n",
    "## this prevents ssh from searching all availble keys\n",
    "extrassh = -o IdentitiesOnly=yes\n",
    "\n",
    "\n",
    "## each 'job' must include at minimum the keys \"localpath\" and \"remotepath\"\n",
    "## other keys are optional (see the example below)\n",
    "## add an `=` to the beginning of a job to disable it\n",
    "## copy this TEMPLATE and remove the `#` to label each job\n",
    "[#TEMPLATE]\n",
    "## `direction`: optional -- not required (defaults to local-remote)\n",
    "direction = <direction of sync from: local-remote or from: remote-local>\n",
    "# direction = local-remote\n",
    "## `user`: optional -- not required for local syncs that do not use ssh\n",
    "user = <remote username>\n",
    "# user = jbuck\n",
    "\n",
    "## `remotehost`: optional -- not required for local syncs that do not use ssh\n",
    "remotehost = <remote ip or host name>\n",
    "# remotehost = backupserver.local\n",
    "\n",
    "## `sshkey`: optional -- not required for local syncs that do not use ssh\n",
    "sshkey = <optional: path to private ssh key>\n",
    "\n",
    "## `localpath`: required \n",
    "localpath = <local path to sync from -- mind the trailing `/`>\n",
    "# localpath = /Users/jbuck/Documents <-- this will sync the dir\n",
    "# localpath = /Users/jbuck/Documents/ <-- this will sync the contents only\n",
    "## be sure to escape spaces in path names!\n",
    "# localpath = /Users/jbuck/path\\ with/lots\\ of/spaces\n",
    "\n",
    "## `remotepath`: required\n",
    "remotepath = <remote path to sync into -- mind the trailing `/`>\n",
    "\n",
    "## `exclude`: optional\n",
    "exclude = <comma separated list of patterns to exclude from sync>\n",
    "# exclude = .DS_Store, data_base, /Downloads, /Applications\n",
    "\n",
    "## `log_file`: optional\n",
    "log_file = <path to log file for this job - each job can have a different log file>\n",
    "# log_file = ~/jobs.log\n",
    "\n",
    "## `timeout`: optional\n",
    "timeout = <seconds before rsync job times out (default: 'None' (no timeout))>\n",
    "# timeout = 600\n",
    "# timeout = None\n",
    "\n",
    "## `kill`: optional\n",
    "kill = <True/False - kill the job after the timeout expires (default: False)>\n",
    "# kill = False\n",
    "\n",
    "## `max_log`: optional\n",
    "max_log = <max log size in bytes before rollover (1048576 bytes == 1 megabyte) (default: 0 no limit)>\n",
    "# max_log = 5242880\n",
    "\n",
    "\n",
    "## Local sync example (disabled)\n",
    "## sync the entire directory `foo` into `ColdStorage`\n",
    "[#Foo -> Bar Local Sync]\n",
    "localpath = /Users/jbuck/Documents/foo\n",
    "remotepath = /Volumes/ColdStorage/\n",
    "\n",
    "\n",
    "## Remote sync over ssh with specific ssh key (disabled)\n",
    "## this is particularly useful when using restricted rsync at the remote end\n",
    "[#iMac JBuck -> Backup Host]\n",
    "user = jbuck\n",
    "remotehost = backups.local\n",
    "sshkey = /Users/jbuck/.ssh/id_rsa-backups\n",
    "localpath = /Users/jbuck/Documents\n",
    "## Note: this is the path **relative** to the remote filesystem\n",
    "## Restricted rsync exposes only exposes a portion of the remote file system\n",
    "## that portion is treated as the \"root\" of the file system\n",
    "remotepath = /iMac.backups/\n",
    "exclude = .AppleDouble, .DS_Store, .git, .local, /Library, /Application*, /Music\n",
    "timeout = 600\n",
    "kill = False\n",
    "log_file = ~/documents_rsync.log\n",
    "# 5 mB = 52428800 bytes\n",
    "max_log = 52428800'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=f'{APP_NAME} v{VERSION} -- run complex rsync jobs from an ini file')\n",
    "    parser.add_argument('-v', '--verbose', action='count', default=0, help='enable verbose output -- can be added multiple times')\n",
    "    parser.add_argument('-d', '--dry_run', dest='dry_run', action='store_true', default=False, help='set rsync --dry-run')\n",
    "    parser.add_argument('-V', '--version', dest='version', action='store_true', default=False, help='display version and exit')\n",
    "    args, unknown_args = parser.parse_known_args()\n",
    "    \n",
    "    return args, unknown_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config(file):\n",
    "    file = Path(file)\n",
    "    \n",
    "    if not file.exists():\n",
    "        file.parent.mkdir(mode=0o750, parents=True, exist_ok=True)\n",
    "        try:\n",
    "            out_file = open(file, 'w')\n",
    "            out_file.writelines(sample_config())\n",
    "            out_file.close()\n",
    "        except OSError as e:\n",
    "            do_exit(e, 2)\n",
    "\n",
    "    config = configparser.ConfigParser()\n",
    "        \n",
    "    config.read(file)\n",
    "    \n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_job(job):\n",
    "    expected_keys=EXPECTED_JOB_KEYS\n",
    "    parsed_job = {}\n",
    "    for key in expected_keys:\n",
    "        try:\n",
    "            parsed_job[key] = job[key]\n",
    "        except KeyError:\n",
    "            parsed_job[key] = expected_keys[key]\n",
    "    return parsed_job "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_config(config):\n",
    "    '''build dictionary from configparser section using expected key/values'''\n",
    "    \n",
    "    expected_base_keys = EXPECTED_BASE_KEYS\n",
    "    expected_ssh_keys = EXPECTED_SSH_KEYS\n",
    "    \n",
    "    base_config = {}\n",
    "    ssh_opts = {}\n",
    "    \n",
    "    for key in expected_base_keys:\n",
    "        try:\n",
    "            base_config[key] = config['%base_config'][key]\n",
    "        except KeyError:\n",
    "            base_config[key] = expected_base_keys[key]\n",
    "    \n",
    "    for key in expected_ssh_keys:\n",
    "        try:\n",
    "            ssh_opts[key] = config['%ssh_opts'][key]\n",
    "        except KeyError:\n",
    "            ssh_opts[key] = expected_ssh_keys[key]\n",
    "    return (base_config, ssh_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_value(string):\n",
    "    '''attempt to normalize values for by converting strings into boolean, or None for:\n",
    "        'True', 'False', 'None'\n",
    "        \n",
    "    Args:\n",
    "        value(`str`): value containing true, false, yes, no, none\n",
    "    \n",
    "    Raises:\n",
    "        TypeError if value is not of type `str`\n",
    "    \n",
    "    Returns:\n",
    "        bool or None'''\n",
    "    \n",
    "    if not isinstance(string, str):\n",
    "        raise TypeError(f'{value} is not type `str`')\n",
    "    \n",
    "    true = ['true', 'yes', 'ok', '1']\n",
    "    false = ['false', 'no', '0']\n",
    "    none = ['none']\n",
    "    \n",
    "    values_dict = {True: true, False: false, None: none}\n",
    "    ret_val = None\n",
    "    \n",
    "    for key, value in values_dict.items():\n",
    "        if string.lower() in value:\n",
    "            ret_val = key\n",
    "            break\n",
    "        else:\n",
    "            ret_val = None\n",
    "    \n",
    "    return ret_val\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rsync_command(name, job, base_config, ssh_opts, tempdir, dry_run=False, verbose=False):\n",
    "    '''build an rsync from ini file\n",
    "    \n",
    "    Args:\n",
    "        name(`str`): name of the job -- used for identifying exclude file\n",
    "        job(`dict`): individual job from ini \n",
    "        base_config(`dict`): base_config from ini\n",
    "        ssh_opts(`dict`): ssh_opts from ini\n",
    "        tempdir(`Path`): path to temporary directory for exclude files\n",
    "        dry_run(`bool`): add `--dry-run` to rsync command for testing\n",
    "        verbose(`int`): add n `-v` to rsync command for increased debugging\n",
    "    \n",
    "    Returns:\n",
    "        string -- rsync command'''\n",
    "    \n",
    "    name = re.sub(r'[\\W_]+', '', name) + str(uuid.uuid4())\n",
    "    \n",
    "    rsync_command = []\n",
    "    ssh_command = ''\n",
    "    tempdir = Path(tempdir)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # get the rsync binary path\n",
    "    if base_config['rsync_bin'] == 'None' or not base_config['rsync_bin']:\n",
    "        rsync_bin = None\n",
    "    else:\n",
    "        rsync_bin = Path(base_config['rsync_bin'])\n",
    "            \n",
    "    if not rsync_bin:\n",
    "        try:\n",
    "            stream = os.popen('which rsync')\n",
    "            rsync_bin = Path(stream.read().rstrip('\\n'))\n",
    "        except Exception as e:\n",
    "            do_exit(e, 1)\n",
    "    \n",
    "    if not rsync_bin:\n",
    "        do_exit(f'could not locate rsync binary in `$PATH`\\nconsider adding:\\n\"rsync_bin=/path/to/rsync\"\\n to [%base_config] section of {CONFIG_PATH}')\n",
    "        \n",
    "    if not rsync_bin.is_file():\n",
    "        do_exit(f'{rsync_bin} does not appear to exist.\\nconsider udating:\\n\"rsync_bin = /path/to/rsync\"\\n to [%base_config] section of {CONFIG_PATH}')\n",
    "    \n",
    "    # add the binary\n",
    "    rsync_command.append(rsync_bin.as_posix())\n",
    "    # add the options from the ini file\n",
    "    rsync_command.append(base_config['rsync_options'])\n",
    "    \n",
    "    # add additional options from the args\n",
    "    if dry_run:\n",
    "        rsync_command.append('--dry-run')\n",
    "        \n",
    "    if verbose:\n",
    "        rsync_command.append('-'+'v'*verbose)\n",
    "    \n",
    "    rsync_command.append(base_config['delete_options'])\n",
    "    \n",
    "    if job['sshkey']:\n",
    "#             ssh_command = f'ssh -o IdentitiesOnly=yes -i {job[\"sshkey\"]}'\n",
    "        ssh_command = f'ssh {ssh_opts[\"extrassh\"]} -i {job[\"sshkey\"]}'\n",
    "        \n",
    "    if len(ssh_command) > 0:\n",
    "        rsync_command.append(f'-e \"{ssh_command}\"')\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        exclude_file = open(tempdir/name, 'w')\n",
    "    except Exception as e:\n",
    "        do_exit(f'{e} while processing {name}', 2)\n",
    "    \n",
    "\n",
    "    if job['exclude']:\n",
    "        # read the exclude string and split into list\n",
    "        exclude_list = [x.strip() for x in job['exclude'].split(',')]\n",
    "        # write list out to file\n",
    "        for l in exclude_list:\n",
    "            exclude_file.write(f'{l}\\n')\n",
    "\n",
    "        rsync_command.append(f'--exclude-from={tempdir/name}')\n",
    "\n",
    "    if not job['localpath']:\n",
    "        do_exit(f'no localpath specified for job: {name}')\n",
    "    \n",
    "#     rsync_command.append(job['localpath'])\n",
    "    localpath = job['localpath']\n",
    "    # add dobule quotes to protect spaces in filenames\n",
    "    localpath = f'\\\"{localpath}\\\"'\n",
    "    \n",
    "    if not job['remotepath']:\n",
    "        do_exit(f'no remote path specified for job {name}')\n",
    "    else:\n",
    "        remotepath = job['remotepath']    \n",
    "        # add double quotes to protect spaces in filenames\n",
    "        remotepath = f'\\\"{remotepath}\\\"'\n",
    "    \n",
    "    # build a `user@remote.host:/path/` string if a user was specified\n",
    "    if job['user']:\n",
    "        remotepath = f\"{job['user']}@{job['remotehost']}:{remotepath}\"\n",
    "    \n",
    "    if job['direction'] == 'remote-local':\n",
    "        rsync_command.append(remotepath)\n",
    "        rsync_command.append(localpath)\n",
    "    else:\n",
    "        rsync_command.append(localpath)\n",
    "        rsync_command.append(remotepath)\n",
    "    \n",
    "#     set_trace()\n",
    "    return shlex.split(' '.join(rsync_command))\n",
    "#     return rsync_command\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multi_line_string():\n",
    "    '''multi-line string object \n",
    "    \n",
    "    each time  multi_line_string.string is set equal to a string, it is added to \n",
    "    the existing string with a new line character\n",
    "    \n",
    "    Properties:\n",
    "        string(`str`): string'''\n",
    "\n",
    "    def __init__(self, s=''):\n",
    "        self._string = ''\n",
    "        self.append(s)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.string)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return(str(self.string))\n",
    "    \n",
    "    @property\n",
    "    def string(self):\n",
    "        return self._string\n",
    "    \n",
    "    @string.setter\n",
    "    def string(self, s):\n",
    "        self._string = s\n",
    "    \n",
    "    def append(self, s):\n",
    "        self._string = self._string + s + '\\n'\n",
    "    \n",
    "    def clear(self):\n",
    "        self._string = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_exit(e, exit_status=99):\n",
    "    '''try to handle exits'''\n",
    "    print(f'{APP_NAME} v{VERSION}')\n",
    "    print(e)\n",
    "    sys.exit(exit_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():    \n",
    "    def do_exit(e, exit_status=99):\n",
    "        # redefine locally to also handle cleanup of temp dirs\n",
    "        '''try to handle exits and cleanup'''\n",
    "        cleanup()\n",
    "        print(f'{APP_NAME} v{VERSION}')\n",
    "        print(e)\n",
    "        sys.exit(exit_status)\n",
    "\n",
    "    def cleanup():\n",
    "        if tempdir:\n",
    "            try:\n",
    "                shutil.rmtree(tempdir)\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                exit(2)\n",
    "\n",
    "        if log_output:\n",
    "            try:\n",
    "                log_output.close()\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                exit(2)\n",
    "            \n",
    "    \n",
    "    # declare these so cleanup() can function everywhere\n",
    "    tempdir = None\n",
    "    log_output = None     \n",
    "\n",
    "    # get the command line arguments\n",
    "    args, unknown_args = parse_args()\n",
    "\n",
    "    if len(unknown_args) > 0:\n",
    "        do_exit(f'Unknown arguments: {unknown_args}', 1)\n",
    "    \n",
    "    # print version, exit\n",
    "    if args.version:\n",
    "        do_exit('', 0)\n",
    "    \n",
    "    if args.verbose > 0:\n",
    "        verbose = args.verbose\n",
    "    else:\n",
    "        verbose = False   \n",
    "   \n",
    "    # create tempdir for exclude files\n",
    "    try:\n",
    "        tempdir = tempfile.mkdtemp()\n",
    "    except Exception as e:\n",
    "        do_exit(e, 2)            \n",
    "    \n",
    "    # build configuration\n",
    "    config_file = Path(CONFIG_PATH)/CONFIG_FILE\n",
    "    config = get_config(config_file)\n",
    "    base_config, ssh_opts = parse_config(config)\n",
    "\n",
    "    # get the list of jobs\n",
    "    jobs = []\n",
    "    for section in config.sections():\n",
    "        # split out the configuration from the jobs\n",
    "        #  ignore any job that begins with a literal '='\n",
    "        if not (section.startswith('%') or section.startswith('#')):\n",
    "            jobs.append(section)\n",
    "    \n",
    "    if len(jobs) < 1:\n",
    "        do_exit(f'ERROR: no jobs are defined.\\nEdit {config_file} to create jobs', 1)\n",
    "\n",
    "    parsed_jobs = {}\n",
    "    # sanitize the jobs, build job dictionary with the appropriate keys\n",
    "    for job in jobs:\n",
    "        parsed_jobs[job] = (parse_job(config[job]))\n",
    "\n",
    "    # build rsync commands as lists using job configuration\n",
    "    rsync_commands = {}\n",
    "    for job in parsed_jobs:\n",
    "#         set_trace()\n",
    "        rsync_commands[job] = build_rsync_command(name=job, job=parsed_jobs[job], base_config=base_config, ssh_opts=ssh_opts, \n",
    "                            tempdir=tempdir, dry_run=args.dry_run, verbose=verbose)\n",
    "\n",
    "    \n",
    "    \n",
    "    # run the jobs\n",
    "    for job, command in rsync_commands.items():\n",
    "        collected_output = multi_line_string('\\n')\n",
    "        collected_output.append('-='*30)\n",
    "        collected_output.append(f'{APP_NAME} v{VERSION}')\n",
    "        collected_output.append(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))        \n",
    "        collected_output.append(f'running job: [{job}]')\n",
    "        collected_output.append(f\"\\ncommand: {' '.join(command)}\\n\")\n",
    "\n",
    "        \n",
    "        # set the output file for the log\n",
    "        log_file = Path('/dev/null').absolute()\n",
    "        \n",
    "        try:\n",
    "            log_file = Path(parsed_jobs[job]['log_file']).expanduser().absolute()\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            # open with buffering = 1 to ensure lines are written in the correct order\n",
    "            # Without this option the header may be written after the rsync information \n",
    "            log_output = open(log_file, 'a', buffering=1)\n",
    "        except OSError as e:\n",
    "            do_exit(f'error opening log file ({log_file}): {e}')\n",
    "            \n",
    "        # log progress thus far\n",
    "        log_output.write(str(collected_output))\n",
    "        if verbose:\n",
    "            print(collected_output)\n",
    "            \n",
    "        # clear the collected output\n",
    "        collected_output.clear()\n",
    "        \n",
    "        # get the timeout and kill values\n",
    "        timeout = parsed_jobs[job]['timeout']\n",
    "        if timeout == 'None':\n",
    "            timeout = None\n",
    "        else:\n",
    "            try:\n",
    "                 timeout = int(timeout)            \n",
    "            except TypeError:\n",
    "                do_exit(f'TypeError in {job}: timeout = {timeout} -- expected `integer` or `None`', 2)\n",
    "        \n",
    "        kill = parsed_jobs[job]['kill']\n",
    "        \n",
    "        if kill == 'False':\n",
    "            kill = False\n",
    "        elif kill == 'True':\n",
    "            kill = True\n",
    "        else:\n",
    "            do_exit(f'TypeError in {job}: kill = {kill} -- expected `True/False`', 2)\n",
    "            \n",
    "        # run the command\n",
    "        process = subprocess.Popen(command, \n",
    "                                 stderr=subprocess.STDOUT, \n",
    "                                 stdout=log_output, \n",
    "                                 universal_newlines=True)\n",
    "        \n",
    "        # check on the status\n",
    "        try:\n",
    "            out = process.communicate(timeout=timeout)\n",
    "        except subprocess.TimeoutExpired:\n",
    "            if kill:\n",
    "                process.kill()\n",
    "                collected_output.append(f'timeout for job {job} expired, process was killed')\n",
    "            else:\n",
    "                collected_output.append(f'timeout for job {job} expired, process was not killed; continuing')\n",
    "        \n",
    "        max_log = parsed_jobs[job]['max_log']\n",
    "        \n",
    "        try:\n",
    "            max_log = int(max_log)\n",
    "        except TypeError:\n",
    "            do_exit(f'TypeError in {job}: max_log = {max_log} -- expected `integer`', 2)\n",
    "        \n",
    "        if log_file.stat().st_size > max_log:\n",
    "            log_archive = Path(str(log_file)+'.1')\n",
    "            try:\n",
    "                shutil.move(log_file, log_archive)\n",
    "            except (FileNotFoundError, OSError):\n",
    "                print(f'could not move {log_file} -> {log_archive}')\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        collected_output.append(f\"completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        collected_output.append(f'[{job}] done')\n",
    "        \n",
    "        if verbose:\n",
    "            print(collected_output)\n",
    "        log_output.write(str(collected_output)) \n",
    "        \n",
    "        log_output.close()\n",
    "    \n",
    "#     set_trace()\n",
    "\n",
    "    cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    job = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_args_initial = sys.argv\n",
    "sys.argv.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv.extend(['-v', '-d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.argv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.core.debugger import set_trace"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automate_rsync-d-A0v8x-",
   "language": "python",
   "name": "automate_rsync-d-a0v8x-"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
