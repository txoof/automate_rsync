{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting automate_rsync.ipynb to automate_rsync.py\n",
      "********** #!/usr/bin/env python3 **********\n",
      "[NbConvertApp] Converting notebook automate_rsync.ipynb to python\n"
     ]
    }
   ],
   "source": [
    "!/Users/aaronciuffo/bin/develtools/nbconvert automate_rsync.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import logging\n",
    "import tempfile\n",
    "import uuid\n",
    "import re\n",
    "import shlex\n",
    "import subprocess\n",
    "import argparse\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "VERSION = '3.0.03-rc1'\n",
    "APP_NAME = 'automate_rsync'\n",
    "DEVEL_NAME = 'com.txoof'\n",
    "CONFIG_FILE = f'{APP_NAME}.ini'\n",
    "\n",
    "\n",
    "EXPECTED_BASE_KEYS = {'rsync_options': '',\n",
    "                      'delete_options': '',\n",
    "                      }\n",
    "\n",
    "EXPECTED_JOB_KEYS = {'user': None,\n",
    "                     'remotehost': None,\n",
    "                     'sshkey': None,\n",
    "                     'localpath': None,\n",
    "                     'remotepath': None,\n",
    "                     'exclude': [],\n",
    "                     'log_file': '/dev/null',\n",
    "                     'max_log': 0,\n",
    "                     'timeout': None,\n",
    "                     'kill': False                     \n",
    "                    }\n",
    "\n",
    "EXPECTED_SSH_KEYS = {'extrassh': ''}\n",
    "\n",
    "CONFIG_PATH = Path(f'~/.config/{DEVEL_NAME}.{APP_NAME}').expanduser().absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_config():\n",
    "    return '''[%base_config]\n",
    "## options to use for all rsync jobs\n",
    "rsync_options = -a -z\n",
    "## deletion strategies to use (leave blank for none)\n",
    "delete_options = --delete-excluded\n",
    "# \n",
    "\n",
    "[%ssh_opts]\n",
    "## extra options to pass to the ssh module\n",
    "## -e \"ssh <extrassh>\"\n",
    "## -o IdentitiesOnly=yes forces the use of one single key file\n",
    "## this prevents ssh from searching all availble keys\n",
    "extrassh = -o IdentitiesOnly=yes\n",
    "\n",
    "\n",
    "## each 'job' must include at minimum the keys \"localpath\" and \"remotepath\"\n",
    "## other keys are optional (see the example below)\n",
    "## add an `=` to the beginning of a job to disable it\n",
    "\n",
    "\n",
    "## copy this TEMPLATE and remove the `=` to label each job\n",
    "[=TEMPLATE]\n",
    "## not required for local syncs that do not use ssh\n",
    "user = <optional: remote username>\n",
    "\n",
    "## not required for local syncs that do not use ssh\n",
    "remotehost = <optional: ip or host name>\n",
    "\n",
    "## not required for local syncs that do not use ssh\n",
    "sshkey = <optional: path to private ssh key>\n",
    "\n",
    "## required\n",
    "localpath = <local path to sync from -- mind the trailing `/`>\n",
    "# localpath = /Users/jbuck/Documents <-- this will sync the dir\n",
    "# localpath = /Users/jbuck/Documents/ <-- this will sync the contents only\n",
    "\n",
    "## required\n",
    "remotepath = <remote path to sync into -- mind the trailing `/`>\n",
    "\n",
    "## optional\n",
    "exclude = <comma separated list of patterns to exclude from sync (default: None)>\n",
    "# exclude = .DS_Store, data_base, /Downloads, /Applications\n",
    "\n",
    "## optional \n",
    "log_file = <path to log file for this job (default: /dev/null)>\n",
    "# log_file = ~/Documents.log\n",
    "\n",
    "## optional\n",
    "timeout = <seconds before rsync job times out (default: None (no timeout))>\n",
    "# timeout = 600\n",
    "\n",
    "## optional\n",
    "kill = <True/False - kill the job after the timeout expires (default: False)>\n",
    "# kill = False\n",
    "\n",
    "## optional\n",
    "## when max size is reached, the log will be rolled over to log_file.1\n",
    "max_log = <max log size in bytes (1048576 bytes == 1 megabyte) (default: 0 no limit)>\n",
    "# max_log = 5242880\n",
    "\n",
    "\n",
    "## Local sync example (disabled)\n",
    "## sync the entire directory `foo` into `ColdStorage`\n",
    "[=Foo -> Bar Local Sync]\n",
    "localpath = /Users/jbuck/Documents/foo\n",
    "remotepath = /Volumes/ColdStorage/\n",
    "\n",
    "\n",
    "## Remote sync over ssh with specific ssh key (disabled)\n",
    "## this is particularly useful when using restricted rsync at the remote end\n",
    "[=iMac JBuck -> Backup Host]\n",
    "user = jbuck\n",
    "remotehost = backups.local\n",
    "sshkey = /Users/jbuck/.ssh/id_rsa-backups\n",
    "localpath = /Users/jbuck/Documents\n",
    "## Note: this is the path **relative** to the remote filesystem\n",
    "## Restricted rsync exposes only exposes a portion of the remote file system\n",
    "## that portion is treated as the \"root\" of the file system\n",
    "remotepath = /iMac.backups/\n",
    "exclude = .AppleDouble, .DS_Store, .git, .local, /Library, /Application*, /Music'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=f'{APP_NAME} v{VERSION} -- run complex rsync jobs from an ini file')\n",
    "    parser.add_argument('-v', '--verbose', action='count', default=0, help='enable verbose output -- can be added multiple times')\n",
    "    parser.add_argument('-d', '--dry_run', dest='dry_run', action='store_true', default=False, help='set rsync --dry-run')\n",
    "    parser.add_argument('-V', '--version', dest='version', action='store_true', default=False, help='display version and exit')\n",
    "    args, unknown_args = parser.parse_known_args()\n",
    "    \n",
    "    return args, unknown_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config(file):\n",
    "    file = Path(file)\n",
    "    \n",
    "    if not file.exists():\n",
    "        file.parent.mkdir(mode=0o750, parents=True, exist_ok=True)\n",
    "        try:\n",
    "            out_file = open(file, 'w')\n",
    "            out_file.writelines(sample_config())\n",
    "            out_file.close()\n",
    "        except OSError as e:\n",
    "            do_exit(e, 2)\n",
    "\n",
    "    config = configparser.ConfigParser()\n",
    "        \n",
    "    config.read(file)\n",
    "    \n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_job(job):\n",
    "    expected_keys=EXPECTED_JOB_KEYS\n",
    "    parsed_job = {}\n",
    "    for key in expected_keys:\n",
    "        try:\n",
    "            parsed_job[key] = job[key]\n",
    "        except KeyError:\n",
    "            parsed_job[key] = expected_keys[key]\n",
    "    return parsed_job "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_config(config):\n",
    "    '''build dictionary from configparser section using expected key/values'''\n",
    "    \n",
    "    expected_base_keys = EXPECTED_BASE_KEYS\n",
    "    expected_ssh_keys = EXPECTED_SSH_KEYS\n",
    "    \n",
    "    base_config = {}\n",
    "    ssh_opts = {}\n",
    "    \n",
    "    for key in expected_base_keys:\n",
    "        try:\n",
    "            base_config[key] = config['%base_config'][key]\n",
    "        except KeyError:\n",
    "            base_config[key] = expected_base_keys[key]\n",
    "    \n",
    "    for key in expected_ssh_keys:\n",
    "        try:\n",
    "            ssh_opts[key] = config['%ssh_opts'][key]\n",
    "        except KeyError:\n",
    "            ssh_opts[key] = expected_ssh_keys[key]\n",
    "    return (base_config, ssh_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rsync_command(name, job, base_config, ssh_opts, tempdir, dry_run=False, verbose=False):\n",
    "    '''build an rsync from ini file\n",
    "    \n",
    "    Args:\n",
    "        name(`str`): name of the job -- used for identifying exclude file\n",
    "        job(`dict`): individual job from ini \n",
    "        base_config(`dict`): base_config from ini\n",
    "        ssh_opts(`dict`): ssh_opts from ini\n",
    "        tempdir(`Path`): path to temporary directory for exclude files\n",
    "        dry_run(`bool`): add `--dry-run` to rsync command for testing\n",
    "        verbose(`int`): add n `-v` to rsync command for increased debugging\n",
    "    \n",
    "    Returns:\n",
    "        string -- rsync command'''\n",
    "    \n",
    "    name = re.sub(r'[\\W_]+', '', name) + str(uuid.uuid4())\n",
    "    \n",
    "    rsync_command = []\n",
    "    ssh_command = ''\n",
    "    tempdir = Path(tempdir)\n",
    "    \n",
    "    # get the rsync binary path\n",
    "    try:\n",
    "        stream = os.popen('which rsync')\n",
    "        rsync_bin = stream.read()\n",
    "    except Exception as e:\n",
    "        do_exit(e, 1)\n",
    "    \n",
    "    # add the binary\n",
    "    rsync_command.append(rsync_bin)\n",
    "    # add the options from the ini file\n",
    "    rsync_command.append(base_config['rsync_options'])\n",
    "    \n",
    "    # add additional options from the args\n",
    "    if dry_run:\n",
    "        rsync_command.append('--dry-run')\n",
    "        \n",
    "    if verbose:\n",
    "        rsync_command.append('-'+'v'*verbose)\n",
    "    \n",
    "    rsync_command.append(base_config['delete_options'])\n",
    "    \n",
    "    if job['sshkey']:\n",
    "            ssh_command = f'ssh -o IdentitiesOnly=yes -i {job[\"sshkey\"]}'\n",
    "        \n",
    "    if len(ssh_command) > 0:\n",
    "        rsync_command.append(f'-e \"{ssh_command}\"')\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        exclude_file = open(tempdir/name, 'w')\n",
    "    except Exception as e:\n",
    "        do_exit(f'{e} while processing {name}', 2)\n",
    "    \n",
    "\n",
    "    if job['exclude']:\n",
    "        # read the exclude string and split into list\n",
    "        exclude_list = [x.strip() for x in job['exclude'].split(',')]\n",
    "        # write list out to file\n",
    "        for l in exclude_list:\n",
    "            exclude_file.write(f'{l}\\n')\n",
    "\n",
    "        rsync_command.append(f'--exclude-from={tempdir/name}')\n",
    "    \n",
    "    if not job['localpath']:\n",
    "        do_exit(f'no localpath specified for job: {name}')\n",
    "    \n",
    "    rsync_command.append(job['localpath'])\n",
    "    \n",
    "    if not job['remotepath']:\n",
    "        do_exit(f'no remote path specified for job {name}')\n",
    "    else:\n",
    "        remotepath = job['remotepath']    \n",
    "    \n",
    "    # build a `user@remote.host:/path/` string if a user was specified\n",
    "    if job['user']:\n",
    "        remotepath = f\"{job['user']}@{job['remotehost']}:{remotepath}\"\n",
    "    \n",
    "    rsync_command.append(remotepath)\n",
    "    \n",
    "#     rsync_command.append(f\">> {job['log_file']} 2>&1\")\n",
    "    \n",
    "    return shlex.split(' '.join(rsync_command))\n",
    "#     return rsync_command\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multi_line_string():\n",
    "    '''multi-line string object \n",
    "    \n",
    "    each time  multi_line_string.string is set equal to a string, it is added to \n",
    "    the existing string with a new line character\n",
    "    \n",
    "    Properties:\n",
    "        string(`str`): string'''\n",
    "\n",
    "    def __init__(self, s=''):\n",
    "        self._string = ''\n",
    "        self.append(s)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.string)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return(str(self.string))\n",
    "    \n",
    "    @property\n",
    "    def string(self):\n",
    "        return self._string\n",
    "    \n",
    "    @string.setter\n",
    "    def string(self, s):\n",
    "        self._string = s\n",
    "    \n",
    "    def append(self, s):\n",
    "        self._string = self._string + s + '\\n'\n",
    "    \n",
    "    def clear(self):\n",
    "        self._string = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():    \n",
    "    def do_exit(e, exit_status=99):\n",
    "        '''try to handle exits and cleanup'''\n",
    "        cleanup()\n",
    "        print(f'{APP_NAME} v{VERSION}')\n",
    "        print(e)\n",
    "        sys.exit(exit_status)\n",
    "\n",
    "    def cleanup():\n",
    "        if tempdir:\n",
    "            try:\n",
    "                shutil.rmtree(tempdir)\n",
    "            except FileNotFoundError:\n",
    "                pass\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                exit(2)\n",
    "                \n",
    "        if log_output:\n",
    "            try:\n",
    "                log_output.close()\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                exit(2)\n",
    "    \n",
    "    # declare these so cleanup() can function everywhere\n",
    "    tempdir = None\n",
    "    log_output = None     \n",
    "\n",
    "    # get the command line arguments\n",
    "    args, unknown_args = parse_args()\n",
    "\n",
    "    if len(unknown_args) > 0:\n",
    "        do_exit(f'Unknown arguments: {unknown_args}', 1)\n",
    "    \n",
    "    # print version, exit\n",
    "    if args.version:\n",
    "        do_exit('', 0)\n",
    "    \n",
    "    if args.verbose > 0:\n",
    "        verbose = args.verbose\n",
    "    else:\n",
    "        verbose = False   \n",
    "   \n",
    "    # create tempdir for exclude files\n",
    "    try:\n",
    "        tempdir = tempfile.mkdtemp()\n",
    "    except Exception as e:\n",
    "        do_exit(e, 2)            \n",
    "    \n",
    "    # build configuration\n",
    "    config_file = Path(CONFIG_PATH)/CONFIG_FILE\n",
    "    config = get_config(config_file)\n",
    "    base_config, ssh_opts = parse_config(config)\n",
    "\n",
    "    # get the list of jobs\n",
    "    jobs = []\n",
    "    for section in config.sections():\n",
    "        # split out the configuration from the jobs\n",
    "        #  ignore any job that begins with a literal '='\n",
    "        if not (section.startswith('%') or section.startswith('=')):\n",
    "            jobs.append(section)\n",
    "    \n",
    "    if len(jobs) < 1:\n",
    "        do_exit(f'ERROR: no jobs are defined.\\nEdit {config_file} to create jobs', 1)\n",
    "\n",
    "    parsed_jobs = {}\n",
    "    # sanitize the jobs, build job dictionary with the appropriate keys\n",
    "    for job in jobs:\n",
    "        parsed_jobs[job] = (parse_job(config[job]))\n",
    "\n",
    "    # build rsync commands as lists using job configuration\n",
    "    rsync_commands = {}\n",
    "    for job in parsed_jobs:\n",
    "        rsync_commands[job] = build_rsync_command(name=job, job=parsed_jobs[job], base_config=base_config, ssh_opts=ssh_opts, \n",
    "                            tempdir=tempdir, dry_run=args.dry_run, verbose=verbose)\n",
    "    \n",
    "    \n",
    "    # run the jobs\n",
    "    for job, command in rsync_commands.items():\n",
    "        collected_output = multi_line_string('\\n')\n",
    "        collected_output.append('-='*30)\n",
    "        collected_output.append(f'{APP_NAME} v{VERSION}')\n",
    "        collected_output.append(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))        \n",
    "        collected_output.append(f'running job: [{job}]')\n",
    "        collected_output.append(f\"\\ncommand: {' '.join(command)}\\n\")\n",
    "\n",
    "        \n",
    "        # set the output file for the log\n",
    "        log_file = Path('/dev/null').absolute()\n",
    "        \n",
    "        try:\n",
    "            log_file = Path(parsed_jobs[job]['log_file']).expanduser().absolute()\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            # open with buffering = 1 to ensure lines are written in the correct order\n",
    "            # Without this option the header may be written after the rsync information \n",
    "            log_output = open(log_file, 'a', buffering=1)\n",
    "        except OSError as e:\n",
    "            do_exit(f'error opening log file ({log_file}): {e}')\n",
    "            \n",
    "        # log progress thus far\n",
    "        log_output.write(str(collected_output))\n",
    "        if verbose:\n",
    "            print(collected_output)\n",
    "            \n",
    "        # clear the collected output\n",
    "        collected_output.clear()\n",
    "        \n",
    "        # get the timeout and kill values\n",
    "        timeout = parsed_jobs[job]['timeout']\n",
    "        if timeout == 'None':\n",
    "            timeout = None\n",
    "        else:\n",
    "            try:\n",
    "                 timeout = int(timeout)            \n",
    "            except TypeError:\n",
    "                do_exit(f'TypeError in {job}: timeout = {timeout} -- expected `integer` or `None`', 2)\n",
    "        \n",
    "        kill = parsed_jobs[job]['kill']\n",
    "        \n",
    "        if kill == 'False':\n",
    "            kill = False\n",
    "        elif kill == 'True':\n",
    "            kill = True\n",
    "        else:\n",
    "            do_exit(f'TypeError in {job}: kill = {kill} -- expected `True/False`', 2)\n",
    "            \n",
    "        # run the command\n",
    "        process = subprocess.Popen(command, \n",
    "                                 stderr=subprocess.STDOUT, \n",
    "                                 stdout=log_output, \n",
    "                                 universal_newlines=True)\n",
    "        \n",
    "        # check on the status\n",
    "        try:\n",
    "            out = process.communicate(timeout=timeout)\n",
    "        except subprocess.TimeoutExpired:\n",
    "            if kill:\n",
    "                process.kill()\n",
    "                collected_output.append(f'timeout for job {job} expired, process was killed')\n",
    "            else:\n",
    "                collected_output.append(f'timeout for job {job} expired, process was not killed; continuing')\n",
    "        \n",
    "        max_log = parsed_jobs[job]['max_log']\n",
    "        \n",
    "        try:\n",
    "            max_log = int(max_log)\n",
    "        except TypeError:\n",
    "            do_exit(f'TypeError in {job}: max_log = {max_log} -- expected `integer`', 2)\n",
    "        \n",
    "        if log_file.stat().st_size > max_log:\n",
    "            log_archive = Path(str(log_file)+'.1')\n",
    "            try:\n",
    "                shutil.move(log_file, log_archive)\n",
    "            except (FileNotFoundError, OSError):\n",
    "                print(f'could not move {log_file} -> {log_archive}')\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        collected_output.append(f\"completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        collected_output.append(f'[{job}] done')\n",
    "        \n",
    "        if verbose:\n",
    "            print(collected_output)\n",
    "        log_output.write(str(collected_output)) \n",
    "        \n",
    "        log_output.close()\n",
    "\n",
    "\n",
    "    cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automate_rsync v3.0.02-rc1\n",
      "Unknown arguments: ['-f', '/Users/aaronciuffo/Library/Jupyter/runtime/kernel-13be3bad-6568-4e3e-9511-3e48b6ac27c7.json']\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    job = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Namespace(dry_run=False, verbose=0, version=False),\n",
       " ['-f',\n",
       "  '/Users/aaronciuffo/Library/Jupyter/runtime/kernel-13be3bad-6568-4e3e-9511-3e48b6ac27c7.json'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automate_rsync-d-A0v8x-",
   "language": "python",
   "name": "automate_rsync-d-a0v8x-"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
